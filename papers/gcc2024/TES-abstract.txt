TES job submission and streamlined data transfers

Task Execution Service (TES, https://www.ga4gh.org/product/task-execution-service-tes/) is an emerging standard mechanism for remote batch job submission, designed for use in complex workflows, and focused on containerized software. 

We introduce our TES over Pulsar (TESP) implementation of a lightweight TES interface layer which leverages on the unifying functionality of Pulsar that hides the diversity of underlying job execution environments (batch systems, file staging etc.). The TES implementation is complemented with improved TES job runner in Galaxy. The runner follows the standard specification strictly, therefore it could be used with another TES implementation too.

On the other hand, the apparent advantages of the layered TESP architecture can be jeopardized by performance problems. In particular, propagating input and output dataset transfers can result in multiple unnecessary file copying (Galaxy -> TES -> Pulsar -> worker node). To avoid these, we extend the schema with delayed file staging -- the data are transfered directly between Galaxy and the job worker node only. Technically, this is implemented by using TES feature of running a sequence of containers rather than one, therefore we can "wrap" the payload job with stage-in and stage-out tasks. TESP translates such a sequence into a single job script passed to Pulsar, ensuring optimal performance as well as availability of the staged-in/out files on the job worker node.

Finally, we push the whole implementation beyond the proof of concept -- we deploy the next generation of UMSA service (special purpose Galaxy installation used by mass spectrometry community, https://umsa.cerit-sc.cz/) using TES job submission only. We will report experience on this production deployment.
